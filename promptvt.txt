import requests
from langchain_aws import ChatBedrockConverse
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import json

# VirusTotal API functions (unchanged from your original code)
def get_ip_report_from_virustotal(ip_address):
    headers = {
        "x-apikey": virustotal_api_key,
        "Content-Type": "application/json"
    }
    response = requests.get(f"{virustotal_api_url}/ip_addresses/{ip_address}", headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        return None

def get_file_report_from_virustotal(hash_file):
    headers = {
        "x-apikey": virustotal_api_key,
        "Content-Type": "application/json"
    }
    response = requests.get(f"{virustotal_api_url}/files/{hash_file}", headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        return None

def get_url_report_from_virustotal(url):
    payload = {"url": url}
    headers1 = {
        "accept": "application/json",
        "x-apikey": virustotal_api_key,
        "Content-Type": "application/x-www-form-urlencoded"
    }
    scan_url = requests.post(f"{virustotal_api_url}/urls", data=payload, headers=headers1)
    print(scan_url.text)

def get_subdomains_from_virustotal(domain):
    # Implementation based on your original code
    else:
        return None

def get_files_from_virustotal(domain):
    headers = {
        "x-apikey": virustotal_api_key,
        "Content-Type": "application/json"
    }
    response = requests.get(f"{virustotal_api_url}/domains/{domain}/communicating_files", headers=headers)
    
    if response.status_code == 200:
        report = response.json()
        data = report["data"]
        file_details_list = []
        for file in data:
            file_attributes = file["attributes"]
            file_details = {
                "file_hash": file.get("id"),
                "file_name": file_attributes.get("names", ["Unknown"]),
                "file_type": file_attributes.get("type_description", "Unknown"),
                "file_size": file_attributes.get("size", "Unknown"),
                "last_analysis_date": file_attributes.get("last_analysis_date", "Unknown"),
                "detection": file_attributes.get("last_analysis_stats", {})
            }
            file_details_list.append(file_details)
        
        return file_details_list
    else:
        return None

def get_dns_domain_from_virustotal(domain):
    # Implementation based on your original code
    pass

# Define tools using Pydantic models for parameters
class IPReportParams(BaseModel):
    ip_address: str = Field(description="The IP address to query")

class FileReportParams(BaseModel):
    hash_file: str = Field(description="The file hash to query")

class URLReportParams(BaseModel):
    url: str = Field(description="The URL to query")

class DomainParams(BaseModel):
    domain: str = Field(description="The domain to query")

# Define tools using langchain's @tool decorator
@tool(args_schema=IPReportParams)
def get_ip_report_from_virustotal_tool(ip_address: str) -> Optional[Dict[str, Any]]:
    """Get the report for an IP address from VirusTotal"""
    return get_ip_report_from_virustotal(ip_address)

@tool(args_schema=FileReportParams)
def get_file_report_from_virustotal_tool(hash_file: str) -> Optional[Dict[str, Any]]:
    """Get the report for a file hash from VirusTotal"""
    return get_file_report_from_virustotal(hash_file)

@tool(args_schema=URLReportParams)
def get_url_report_from_virustotal_tool(url: str) -> Optional[Dict[str, Any]]:
    """Get the report for a URL from VirusTotal"""
    return get_url_report_from_virustotal(url)

@tool(args_schema=DomainParams)
def get_subdomains_from_virustotal_tool(domain: str) -> Optional[Dict[str, Any]]:
    """Get subdomains for a domain from VirusTotal"""
    return get_subdomains_from_virustotal(domain)

@tool(args_schema=DomainParams)
def get_files_from_virustotal_tool(domain: str) -> Optional[List[Dict[str, Any]]]:
    """Get communicating files for a domain from VirusTotal"""
    return get_files_from_virustotal(domain)

@tool(args_schema=DomainParams)
def get_dns_domain_from_virustotal_tool(domain: str) -> Optional[Dict[str, Any]]:
    """Get passive DNS resolutions for a domain from VirusTotal"""
    return get_dns_domain_from_virustotal(domain)

# Initialize ChatBedrockConverse
def initialize_bedrock_client():
    """Initialize the Bedrock client with your preferred model"""
    return ChatBedrockConverse(
        model="anthropic.claude-3-5-sonnet-20241022-v2:0",  # or any other supported model
        region_name="us-east-1",  # specify your AWS region
        # AWS credentials will be picked up from environment variables or IAM role
    )

# Main function to handle conversations with tools
def generate_bedrock_response(messages: List[Dict[str, str]]) -> str:
    """
    Generate response using Bedrock with tool calling capabilities
    
    Args:
        messages: List of message dictionaries with 'role' and 'content' keys
    
    Returns:
        str: The response from the model
    """
    
    # Initialize the Bedrock client
    llm = initialize_bedrock_client()
    
    # Define available tools
    tools = [
        get_ip_report_from_virustotal_tool,
        get_file_report_from_virustotal_tool,
        get_url_report_from_virustotal_tool,
        get_subdomains_from_virustotal_tool,
        get_files_from_virustotal_tool,
        get_dns_domain_from_virustotal_tool
    ]
    
    # Bind tools to the model
    llm_with_tools = llm.bind_tools(tools)
    
    # Convert messages to LangChain format
    langchain_messages = []
    for msg in messages:
        if msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
        elif msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        # Note: Assistant messages would need to be handled differently if you have conversation history
    
    try:
        # Get response from model
        response = llm_with_tools.invoke(langchain_messages)
        
        # Handle tool calls if present
        if response.tool_calls:
            # Execute tool calls and get results
            tool_messages = []
            
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call.get("id", "")
                
                # Find and execute the appropriate tool
                tool_result = None
                for tool in tools:
                    if tool.name == tool_name:
                        try:
                            tool_result = tool.invoke(tool_args)
                        except Exception as e:
                            tool_result = f"Error executing tool: {str(e)}"
                        break
                
                # Create tool message
                from langchain_core.messages import ToolMessage
                tool_messages.append(
                    ToolMessage(
                        content=json.dumps(tool_result) if tool_result else "No result",
                        tool_call_id=tool_id
                    )
                )
            
            # Get final response with tool results
            final_messages = langchain_messages + [response] + tool_messages
            final_response = llm_with_tools.invoke(final_messages)
            
            return final_response.content
        else:
            # No tool calls, return direct response
            return response.content
            
    except Exception as e:
        return f"Error generating response: {str(e)}"

# FastAPI endpoint implementation
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging

# Setup logging
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI()

class QueryRequest(BaseModel):
    user_id: str
    query: str

# Global conversation storage (in production, use a proper database)
last_conversation = []

# Simple conversation starters (same as your original)
simple_conversation_starters = {
    "hello": {"response": "Hello! How can I help you with cybersecurity analysis today?"},
    "hi": {"response": "Hi there! I'm here to help you analyze potential threats using VirusTotal."},
    "help": {"response": "I can help you analyze IPs, file hashes, URLs, and domains using VirusTotal. Just ask me to check something!"}
}

@app.post("/threat")
async def analyze_query(request: QueryRequest):
    """
    Analyze cybersecurity threats using AWS Bedrock and VirusTotal
    """
    global last_conversation
    
    print("client:", request)
    print("type(client):", type(request))
    
    reports = []
    lower_query = request.query.lower()
    logger.info(f"data: {request}")
    
    # Check for simple conversation starters
    if lower_query in simple_conversation_starters:
        predefined = simple_conversation_starters[lower_query]
        response = predefined["response"]
        return {"text": response, "type": "text"}
    
    else:
        # Update the conversation history
        last_conversation = last_conversation[-2:]  # Keep only the last conversation
        # Append the current query to the last conversation
        messages = last_conversation + [{"role": "user", "content": request.query}]
        last_conversation = last_conversation + [{"role": "user", "content": request.query}]
        
        try:
            # Generate initial response from AWS Bedrock
            response = generate_bedrock_response(messages)
            
            # The generate_bedrock_response function now handles tool calls internally
            # and returns the final response as a string
            final_answer = response
            
            # Store the response in conversation history
            last_conversation.append({"role": "assistant", "content": final_answer})
            last_conversation = last_conversation[-2:]  # Keep only last 2 messages
            
            # Store in database (implement your store_db functions)
            # store_db.store_query_response_threat(request.user_id, request.query, final_answer, "text")
            logger.info(f"chat response: {final_answer}")
            
            return {"text": final_answer, "type": "text"}
            
        except Exception as e:
            logger.error(f"Error in analyze_query: {str(e)}")
            final_answer = "Sorry, I couldn't retrieve the report."
            # store_db.store_query_response_threat(request.user_id, request.query, final_answer, "text")
            logger.info(f"chat response: {final_answer}")
            return {"text": final_answer, "type": "text"}

# Alternative implementation that mimics your original OpenAI approach more closely
@app.post("/threat_detailed")
async def analyze_query_detailed(request: QueryRequest):
    """
    Alternative implementation that provides more detailed tool call handling
    similar to your original OpenAI approach
    """
    global last_conversation
    
    reports = []
    lower_query = request.query.lower()
    logger.info(f"data: {request}")
    
    if lower_query in simple_conversation_starters:
        predefined = simple_conversation_starters[lower_query]
        response = predefined["response"]
        return {"text": response, "type": "text"}
    
    else:
        # Update conversation history
        last_conversation = last_conversation[-2:]
        messages = last_conversation + [{"role": "user", "content": request.query}]
        last_conversation = last_conversation + [{"role": "user", "content": request.query}]
        
        try:
            # Initialize the Bedrock client
            llm = initialize_bedrock_client()
            
            # Define available tools
            tools = [
                get_ip_report_from_virustotal_tool,
                get_file_report_from_virustotal_tool,
                get_url_report_from_virustotal_tool,
                get_subdomains_from_virustotal_tool,
                get_files_from_virustotal_tool,
                get_dns_domain_from_virustotal_tool
            ]
            
            # Bind tools to the model
            llm_with_tools = llm.bind_tools(tools)
            
            # Convert to LangChain messages
            from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
            
            langchain_messages = []
            for msg in messages:
                if msg["role"] == "system":
                    langchain_messages.append(SystemMessage(content=msg["content"]))
                elif msg["role"] == "user":
                    langchain_messages.append(HumanMessage(content=msg["content"]))
                # Handle assistant messages if needed
            
            # Get initial response
            response_message = llm_with_tools.invoke(langchain_messages)
            print("response_message:", response_message)
            
            # Handle function calls (similar to your original logic)
            if response_message.tool_calls:
                for tool_call in response_message.tool_calls:
                    function_name = tool_call["name"]
                    function_args = tool_call["args"]
                    print(f"Function arguments: {function_args}")
                    
                    # Call the appropriate VirusTotal function based on the function name
                    report = None
                    if function_name == "get_ip_report_from_virustotal_tool":
                        ip_address = function_args.get("ip_address")
                        report = get_ip_report_from_virustotal(ip_address)
                    elif function_name == "get_file_report_from_virustotal_tool":
                        hash_file = function_args.get("hash_file")
                        report = get_file_report_from_virustotal(hash_file)
                    elif function_name == "get_url_report_from_virustotal_tool":
                        url = function_args.get("url")
                        report = get_url_report_from_virustotal(url)
                    elif function_name == "get_subdomains_from_virustotal_tool":
                        domain = function_args.get("domain")
                        report = get_subdomains_from_virustotal(domain)
                    elif function_name == "get_files_from_virustotal_tool":
                        domain = function_args.get("domain")
                        report = get_files_from_virustotal(domain)
                    elif function_name == "get_dns_domain_from_virustotal_tool":
                        domain = function_args.get("domain")
                        report = get_dns_domain_from_virustotal(domain)
                    
                    if report:
                        reports.append(report)
                
                # Combine all reports into a single context
                combined_reports = {
                    "reports": reports
                }
                
                # If reports were generated, format the report data and append to the conversation
                if combined_reports["reports"]:
                    # Create tool messages for each tool call
                    tool_messages = []
                    for tool_call in response_message.tool_calls:
                        tool_messages.append(ToolMessage(
                            content=json.dumps(combined_reports),
                            tool_call_id=tool_call.get("id", "")
                        ))
                    
                    # Generate a final response to make the output more natural
                    prompt = f'''I am equipped with the knowledge present in the following context:
                    {combined_reports}
                    
                    Please feel free to ask any questions related to this context, and I will do my best to provide accurate and helpful responses. However, I am programmed to stay within the bounds of the provided context, so I may not be able to answer questions that are outside of its scope.
                    
                    Whenever generating an answer the date should be in the format dd/mm/yyyy if present.
                    The answer format should be as follows:
                    1)**Summary**: Summary of the {combined_reports} according to the {request.query} in 5 bullet points. Only list if data is present.
                    2)**Conclusion**: Answer the {request.query} according to the {combined_reports} in natural language.
                    '''
                    
                    final_messages = langchain_messages + [response_message] + tool_messages + [
                        HumanMessage(content=prompt)
                    ]
                    
                    final_response = llm.invoke(final_messages)
                    final_answer = final_response.content
                    
                    # Store the response
                    # store_db.store_query_response_threat(request.user_id, request.query, final_answer, "text")
                    logger.info(f"chat response: {final_answer}")
                    last_conversation.append({"role": "assistant", "content": final_answer})
                    last_conversation = last_conversation[-2:]
                    
                    return {"text": final_answer, "type": "text"}
                else:
                    final_answer = "Sorry, I couldn't retrieve the report."
                    # store_db.store_query_response_threat(request.user_id, request.query, final_answer, "text")
                    logger.info(f"chat response: {final_answer}")
                    return {"text": final_answer, "type": "text"}
            
            # If no function call was made, return the initial response
            last_conversation.append({"role": "assistant", "content": response_message.content})
            last_conversation = last_conversation[-2:]
            # store_db.store_query_response_threat(request.user_id, request.query, response_message.content, "text")
            logger.info(f"Chat response: {response_message.content}")
            return {"text": response_message.content, "type": "text"}
            
        except Exception as e:
            logger.error(f"Error: {str(e)}")
            raise HTTPException(status_code=500, detail=str(e))

# Configuration (you'll need to set these)
virustotal_api_key = "YOUR_VIRUSTOTAL_API_KEY"
virustotal_api_url = "https://www.virustotal.com/api/v3"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)