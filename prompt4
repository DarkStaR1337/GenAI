import os
import json
import pandas as pd
from azure.storage.blob import BlobServiceClient
from langchain_aws import ChatBedrock
from langchain.schema import HumanMessage, SystemMessage
from langchain_experimental.agents import create_csv_agent
from langchain.agents import AgentType
from fastapi import HTTPException
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_demisto_data():
    """
    Fetch data from Azure Blob Storage and return processed DataFrame
    """
    try:
        # Azure Blob Storage connection (keeping this part unchanged)
        connection_string = os.environ.get("BLOB_CONNECTION_STRING")
        container = os.environ.get("container_name")
        filename = "data.json"
        
        blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        container_client = blob_service_client.get_container_client(container)
        blob_client = container_client.get_blob_client(filename)
        blob_data = blob_client.download_blob().readall()
        demisto_data_inc = json.loads(blob_data)
        
        # Process the data
        df_selected = pd.DataFrame.from_dict(demisto_data_inc)
        df_selected = pd.json_normalize(df_selected['data'])
        
        # Select and rename columns
        to_keep = ['id', 'type', 'name', 'severity', 'status', 'closeReason', 'CustomFields.remarks']
        df = df_selected[to_keep]
        df = df.rename(columns={'CustomFields.remarks': 'Remarks', 'closeReason': 'Close_Reason'})
        df = df.fillna("")
        
        # Data transformations
        df.loc[:, 'severity'] = df['severity'].replace([0, 0.5, 1, 2, 3, 4], 
                                                      ['Unknown', 'Informational', 'Low', 'Medium', 'High', 'Critical'])
        df.loc[:, 'status'] = df['status'].replace([0, 1, 2], ['Pending', 'Active', 'Closed'])
        df = df.sort_values(by='id')
        
        return df
        
    except Exception as e:
        logger.error(f"Error fetching Demisto data: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

def get_bedrock_client():
    """
    Initialize and return AWS Bedrock client
    """
    try:
        return ChatBedrock(
            model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",  # Using Claude 3.5 Sonnet
            region_name="ap-southeast-1",  # APAC region
            model_kwargs={
                "max_tokens": 1000,
                "temperature": 0.1,
            }
        )
    except Exception as e:
        logger.error(f"Error initializing Bedrock client: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to initialize AWS Bedrock: {str(e)}")

def analyze_sentiment(text):
    """
    Analyze sentiment using AWS Bedrock Claude
    """
    try:
        if not text or pd.isna(text) or text.strip() == '':
            return 'Neutral'
            
        bedrock_client = get_bedrock_client()
        
        # Create messages for sentiment analysis
        system_message = SystemMessage(
            content="Analyze the sentiment of the following text. Is it positive, neutral, or negative? "
                   "Only give one word as the answer: Positive/Neutral/Negative. If the text is empty or null or has no context "
                   "then the answer should be Neutral."
        )
        
        human_message = HumanMessage(content=f"Analyze the sentiment of the following text: {text}")
        
        messages = [system_message, human_message]
        
        # Get response from Bedrock
        response = bedrock_client.invoke(messages)
        
        # Extract sentiment from response content
        sentiment = response.content.strip()
        
        return sentiment
        
    except Exception as e:
        logger.error(f"Error in sentiment analysis: {str(e)}")
        return 'Neutral'  # Return neutral as fallback instead of raising exception

def sentiment_analysis_ai(df):
    """
    Apply sentiment analysis to the DataFrame using AWS Bedrock
    """
    try:
        # Apply sentiment analysis to remarks column
        df['Sentiment'] = df['Remarks'].apply(
            lambda remark: analyze_sentiment(remark) if pd.notnull(remark) and remark.strip() != '' else 'Neutral'
        )
        
        return df
        
    except Exception as e:
        logger.error(f"Error in sentiment analysis AI: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

def create_bedrock_csv_agent(csv_file_path, prefix=""):
    """
    Create a CSV agent using AWS Bedrock Claude
    """
    try:
        # Initialize AWS Bedrock LLM for CSV agent
        bedrock_llm = ChatBedrock(
            model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",
            region_name="ap-southeast-1",
            model_kwargs={
                "max_tokens": 4000,
                "temperature": 0.1,
            }
        )
        
        # Create CSV agent with AWS Bedrock
        agent = create_csv_agent(
            bedrock_llm,
            csv_file_path,
            verbose=True,
            prefix=prefix,
            agent_type=AgentType.OPENAI_FUNCTIONS,  # This works with Claude as well
            allow_dangerous_code=True,
            agent_executor_kwargs={"handle_parsing_errors": True, "return_only_outputs": True}
        )
        
        return agent
        
    except Exception as e:
        logger.error(f"Error creating CSV agent: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to create CSV agent: {str(e)}")

def query_bedrock_agent(agent, query):
    """
    Query the Bedrock agent and return response
    """
    try:
        result = agent.invoke(query)
        return result['output']
        
    except Exception as e:
        logger.error(f"Error querying Bedrock agent: {str(e)}")
        # Return a fallback response instead of raising exception
        return "I apologize, but I'm having trouble processing your request with the agent. Please try rephrasing your question."

def direct_bedrock_query(query, df):
    """
    Fallback function to query Bedrock directly with DataFrame context
    """
    try:
        bedrock_client = get_bedrock_client()
        
        # Create context from DataFrame (limit to avoid token limits)
        df_summary = df.head(10).to_string()
        
        prompt = f"""
        Based on the following incident data with sentiment analysis:
        
        {df_summary}
        
        Please answer the following question: {query}
        
        Instructions:
        - Always mention the incident ID when referring to specific incidents
        - Use only the information provided in the data
        - If you can't find relevant information, say so clearly
        """
        
        message = HumanMessage(content=prompt)
        response = bedrock_client.invoke([message])
        
        return response.content.strip()
        
    except Exception as e:
        logger.error(f"Direct Bedrock query error: {str(e)}")
        return "I'm sorry, I couldn't process your request at the moment. Please try again."

def process_sentiment_query(query, user_id=None):
    """
    Main processing function that handles the entire sentiment analysis workflow
    """
    try:
        # Step 1: Fetch and process data
        logger.info(f"Processing query: {query}")
        df_sent = get_demisto_data()
        
        if df_sent.empty:
            return {"text": "Demistro data is null", "type": "text", "graph_data": None}
        
        # Step 2: Apply sentiment analysis
        df_final_ai = sentiment_analysis_ai(df_sent)
        
        # Step 3: Save processed data to CSV for agent
        csv_file_path = "final2.csv"
        df_final_ai.to_csv(csv_file_path, index=False)
        
        # Step 4: Create prefix for CSV agent
        prefix = '''
        Do not create your own indexing. Use only the information provided in the file.
        Always mention the incident id corresponding to the information that is being returned.
        '''
        
        # Step 5: Check if query requires graph/chart (you can implement graph_query logic here)
        is_graph_query, graph_type = check_graph_query(query)
        
        if is_graph_query:
            # Handle graph/chart queries (implement your graph logic here)
            graph_data = generate_graph_data(query, df_final_ai, graph_type)
            if graph_data:
                return {
                    "text": "", 
                    "graph_data": graph_data, 
                    "type": "y"
                }
            else:
                return {
                    "text": "Please elaborate your question", 
                    "type": "text", 
                    "graph_data": None
                }
        else:
            # Step 6: Handle regular text queries using Bedrock agent
            try:
                agent = create_bedrock_csv_agent(csv_file_path, prefix)
                response_text = query_bedrock_agent(agent, query)
                
                return {
                    "text": response_text, 
                    "graph_data": None, 
                    "type": "text"
                }
                
            except Exception as agent_error:
                logger.error(f"Agent processing failed: {str(agent_error)}")
                # Fallback to direct query
                fallback_response = direct_bedrock_query(query, df_final_ai)
                return {
                    "text": fallback_response, 
                    "graph_data": None, 
                    "type": "text"
                }
        
    except Exception as e:
        logger.error(f"Error in process_sentiment_query: {str(e)}")
        return {
            "text": "I apologize, but I encountered an error while processing your request. Please try again.", 
            "type": "text", 
            "graph_data": None
        }

def check_graph_query(query):
    """
    Determine if query requires graph/chart visualization
    Implement your existing graph_query logic here
    """
    # TODO: Implement your existing graph detection logic
    # For now, returning False as placeholder
    graph_keywords = ['chart', 'graph', 'plot', 'visualize', 'show', 'distribution', 'trend']
    
    query_lower = query.lower()
    is_graph = any(keyword in query_lower for keyword in graph_keywords)
    
    # Determine graph type based on query
    graph_type = None
    if is_graph:
        if any(word in query_lower for word in ['pie', 'distribution']):
            graph_type = 'pie'
        elif any(word in query_lower for word in ['bar', 'count']):
            graph_type = 'bar'
        elif any(word in query_lower for word in ['line', 'trend', 'time']):
            graph_type = 'line'
        else:
            graph_type = 'bar'  # default
    
    return is_graph, graph_type

def generate_graph_data(query, df, graph_type):
    """
    Generate graph data for visualization
    Implement your existing graph_json logic here
    """
    # TODO: Implement your existing graph generation logic
    # This is a placeholder implementation
    try:
        if graph_type == 'pie':
            # Example: Sentiment distribution
            sentiment_counts = df['Sentiment'].value_counts().to_dict()
            return {
                "chart_type": "pie",
                "data": [{"name": k, "value": v} for k, v in sentiment_counts.items()]
            }
        elif graph_type == 'bar':
            # Example: Status distribution
            status_counts = df['status'].value_counts().to_dict()
            return {
                "chart_type": "bar",
                "data": [{"name": k, "value": v} for k, v in status_counts.items()]
            }
        else:
            return None
            
    except Exception as e:
        logger.error(f"Error generating graph data: {str(e)}")
        return None